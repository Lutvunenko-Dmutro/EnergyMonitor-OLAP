import os
import logging
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from contextlib import contextmanager
import psycopg2
from dotenv import load_dotenv

# --- 1. CONFIGURATION ---
load_dotenv()

# –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

DB_CONFIG = {
    "dbname": os.getenv("DB_NAME", "postgres"),
    "user": os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", "password"),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432")
}

# --- 2. DATABASE HELPER ---
@contextmanager
def get_db_connection():
    """–ë–µ–∑–ø–µ—á–Ω–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î."""
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        yield conn
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î: {e}")
        raise
    finally:
        if conn:
            conn.close()

def get_data(query: str) -> pd.DataFrame:
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö —É DataFrame."""
    with get_db_connection() as conn:
        return pd.read_sql_query(query, conn)

# --- 3. ML FUNCTIONS ---

def run_clustering_analysis():
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –ø—ñ–¥—Å—Ç–∞–Ω—Ü—ñ–π (K-Means)."""
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó (K-Means)...")

    sql = """
    SELECT 
        s.substation_name,
        AVG(l.actual_load_mw) as avg_load,
        STDDEV(l.actual_load_mw) as load_volatility,
        COUNT(a.alert_id) as alert_count
    FROM Substations s
    LEFT JOIN LoadMeasurements l ON s.substation_id = l.substation_id
    LEFT JOIN Alerts a ON s.substation_id = a.substation_id
    GROUP BY s.substation_name;
    """
    df = get_data(sql).fillna(0)

    if df.empty:
        logger.warning("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó.")
        return

    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[['avg_load', 'load_volatility', 'alert_count']])

    # K-Means (n_clusters=3)
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    df['Cluster'] = kmeans.fit_predict(X_scaled)

    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    plt.figure(figsize=(12, 8))
    sns.scatterplot(
        data=df, 
        x='avg_load', 
        y='alert_count', 
        hue='Cluster', 
        palette='viridis', 
        s=150, 
        edgecolor='black'
    )
    plt.title('–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –ü—ñ–¥—Å—Ç–∞–Ω—Ü—ñ–π: –ù–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è vs –ê–≤–∞—Ä—ñ–π–Ω—ñ—Å—Ç—å', fontsize=16)
    plt.xlabel('–°–µ—Ä–µ–¥–Ω—î –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (–ú–í—Ç)')
    plt.ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∞–≤–∞—Ä—ñ–π')
    plt.grid(True, linestyle='--', alpha=0.7)
    
    filename = 'clustering_result.png'
    plt.savefig(filename)
    logger.info(f"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")

    # –í–∏–≤—ñ–¥ –æ–ø–∏—Å—É –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤
    logger.info("–°–µ—Ä–µ–¥–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö:")
    print(df.groupby('Cluster')[['avg_load', 'alert_count']].mean())

def run_classification_prediction():
    """–ü–æ–±—É–¥–æ–≤–∞ –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å (Decision Tree) –∑ –ö–û–ú–ü–ê–ö–¢–ù–ò–ú –¥–∏–∑–∞–π–Ω–æ–º."""
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è (Decision Tree)...")

    sql = """
    SELECT 
        EXTRACT(HOUR FROM l.timestamp) as hour_of_day,
        w.temperature,
        CASE WHEN (l.actual_load_mw / s.capacity_mw) > 0.95 THEN 1 ELSE 0 END as is_critical
    FROM LoadMeasurements l
    JOIN Substations s ON l.substation_id = s.substation_id
    JOIN WeatherReports w ON l.timestamp = w.timestamp AND s.region_id = w.region_id
    LIMIT 50000;
    """
    df = get_data(sql)

    if df.empty or df['is_critical'].sum() == 0:
        logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö (–∞–±–æ –∞–≤–∞—Ä—ñ–π–Ω–∏—Ö —Å—Ç–∞–Ω—ñ–≤) –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ.")
        return

    X = df[['hour_of_day', 'temperature']]
    y = df['is_critical']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    clf = DecisionTreeClassifier(max_depth=3, random_state=42, class_weight='balanced')
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    print("\n--- –ó–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó ---")
    print(classification_report(y_test, y_pred, zero_division=0))

    # --- –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø (COMPACT STYLE) ---
    plt.figure(figsize=(12, 6), dpi=300) 
    
    plot_tree(
        clf, 
        feature_names=['–ì–æ–¥–∏–Ω–∞', '–¢–µ–º–ø. (¬∞C)'], 
        class_names=['–ù–æ—Ä–º–∞', '–ê–≤–∞—Ä—ñ—è'], 
        filled=True,      
        rounded=True,     
        impurity=False,   
        proportion=False, 
        precision=1,      
        fontsize=10,      
        node_ids=False,  
        label='root'      
    )
    
    plt.title('–ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∞–≤–∞—Ä—ñ–π–Ω–∏—Ö —Å—Ç–∞–Ω—ñ–≤', fontsize=14, fontweight='bold')
    
    filename = 'decision_tree.png'
    plt.savefig(filename, bbox_inches='tight', dpi=300) 
    logger.info(f"‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–µ –¥–µ—Ä–µ–≤–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")

# --- 4. MAIN ---
if __name__ == "__main__":
    try:
        run_clustering_analysis()
        run_classification_prediction()
        logger.info("üèÅ ML –∞–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ.")
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
